{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "personalized-incentive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, time, gc\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numba import njit\n",
    "import treelite, treelite_runtime\n",
    "import optuna\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sudden-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_score_bincount(date, weight, resp, action):\n",
    "    count_i = len(np.unique(date))\n",
    "    Pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
    "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "apart-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quarterly-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 32s, sys: 33 s, total: 14min 5s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = '/kaggle/working/input/'\n",
    "# path = '/kaggle/input/jane-street-market-prediction'\n",
    "# train = dt.fread(os.path.join(path, 'train.csv')).to_pandas()\n",
    "# train = train[train['weight'] != 0].reset_index(drop = True)\n",
    "train_data = (\n",
    "    dt.fread(os.path.join(path, 'train.csv'))\n",
    "    .to_pandas()\n",
    "    .query('weight > 0')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "f_mean = train_data.mean()\n",
    "train_data = train_data.fillna(f_mean)\n",
    "\n",
    "feature_names = [c for c in train_data.columns if 'feature' in c]\n",
    "\n",
    "train_data['action'] = (train_data['resp'].values > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wired-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[feature_names].values\n",
    "X_weight = train_data['weight'].values\n",
    "X_date = train_data['date'].values\n",
    "X_resp = train_data['resp'].values\n",
    "y_labels = train_data['action'].values\n",
    "groups = train_data['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "level-constraint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=3,\n",
    "    max_train_group_size=150,\n",
    "    max_test_group_size=60,\n",
    "    group_gap=20\n",
    ")\n",
    "\n",
    "def objectie(trial, cv=cv, cv_fold_func=np.average):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 350, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.10),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.50, 0.90),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 0.90),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 20),\n",
    "        'missing': -999,\n",
    "        'tree_method': 'gpu_hist' \n",
    "    }\n",
    "    aucs = []\n",
    "    for i, (train_idx, valid_idx) in enumerate(cv.split(\n",
    "        X_train,\n",
    "        y_labels,\n",
    "        groups\n",
    "    )):\n",
    "        \n",
    "        d_train = xgb.DMatrix(X_train[train_idx], y_labels[train_idx])\n",
    "        d_valid_x = xgb.DMatrix(X_train[valid_idx])\n",
    "        clf = xgb.train(params=params, dtrain=d_train, num_boost_round=200)\n",
    "        preds = clf.predict(d_valid_x)\n",
    "        auc = utility_score_bincount(\n",
    "            action=preds, \n",
    "            weight=X_weight[valid_idx], \n",
    "            resp=X_resp[valid_idx],\n",
    "            date=X_date[valid_idx],\n",
    "        )\n",
    "        aucs.append(auc)\n",
    "        \n",
    "    print(f'Trial done: AUC values on folds: {aucs}')\n",
    "    return cv_fold_func(aucs)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "induced-philip",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:32:11,467]\u001b[0m A new study created in memory with name: no-name-ecba5849-d16c-471b-bdbd-aa578d892538\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:32:15] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:32:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:32:29] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:32:32,530]\u001b[0m Trial 0 finished with value: 0.29875175656710506 and parameters: {'n_estimators': 451, 'max_depth': 8, 'learning_rate': 0.07032854217178496, 'subsample': 0.5111717881380816, 'colsample_bytree': 0.5353314591052204, 'gamma': 13}. Best is trial 0 with value: 0.29875175656710506.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 0.8962552697013152]\n",
      "[14:32:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:32:44] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:32:52] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:32:56,005]\u001b[0m Trial 1 finished with value: 0.4305193332024578 and parameters: {'n_estimators': 371, 'max_depth': 6, 'learning_rate': 0.029902334245203742, 'subsample': 0.5975051391923565, 'colsample_bytree': 0.5450317291663184, 'gamma': 12}. Best is trial 1 with value: 0.4305193332024578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 1.2915579996073734]\n",
      "[14:33:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:33:07] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:33:14] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:33:17,854]\u001b[0m Trial 2 finished with value: 0.27233211124310536 and parameters: {'n_estimators': 486, 'max_depth': 8, 'learning_rate': 0.020608251117459987, 'subsample': 0.6010389894511073, 'colsample_bytree': 0.6205024907645013, 'gamma': 13}. Best is trial 1 with value: 0.4305193332024578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 0.8169963337293161]\n",
      "[14:33:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:33:29] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:33:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:33:40,619]\u001b[0m Trial 3 finished with value: 0.3519044698146336 and parameters: {'n_estimators': 496, 'max_depth': 9, 'learning_rate': 0.03943734891209041, 'subsample': 0.6269076113082361, 'colsample_bytree': 0.6980215590726776, 'gamma': 12}. Best is trial 1 with value: 0.4305193332024578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 1.0557134094439007]\n",
      "[14:33:44] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:33:50] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:33:56] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:34:00,194]\u001b[0m Trial 4 finished with value: 0.27621066469471595 and parameters: {'n_estimators': 620, 'max_depth': 10, 'learning_rate': 0.08819427633567413, 'subsample': 0.6879072916670839, 'colsample_bytree': 0.679936593564231, 'gamma': 16}. Best is trial 1 with value: 0.4305193332024578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 0.8286319940841479]\n",
      "[14:34:05] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:34:16] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:34:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:34:36,007]\u001b[0m Trial 5 finished with value: 16.40787394186705 and parameters: {'n_estimators': 805, 'max_depth': 6, 'learning_rate': 0.05312271253208954, 'subsample': 0.7847018958411507, 'colsample_bytree': 0.7539817798714861, 'gamma': 0}. Best is trial 5 with value: 16.40787394186705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [3.2234127075539933, -0.0, 46.00020911804715]\n",
      "[14:34:40] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:34:47] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:34:54] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:34:57,667]\u001b[0m Trial 6 finished with value: 0.23655043464898914 and parameters: {'n_estimators': 566, 'max_depth': 3, 'learning_rate': 0.09486469648952532, 'subsample': 0.8842431626306128, 'colsample_bytree': 0.7701064450535957, 'gamma': 16}. Best is trial 5 with value: 16.40787394186705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 0.7096513039469674]\n",
      "[14:35:01] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:35:10] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:35:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:35:25,974]\u001b[0m Trial 7 finished with value: 19.987213651014184 and parameters: {'n_estimators': 639, 'max_depth': 5, 'learning_rate': 0.06770445125481561, 'subsample': 0.84686258213475, 'colsample_bytree': 0.5256755864445335, 'gamma': 0}. Best is trial 7 with value: 19.987213651014184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [3.709521726178821, -0.0, 56.25211922686373]\n",
      "[14:35:30] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:35:44] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:35:59] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:36:09,622]\u001b[0m Trial 8 finished with value: 29.37219944150144 and parameters: {'n_estimators': 456, 'max_depth': 7, 'learning_rate': 0.07727156817375246, 'subsample': 0.7650415798701067, 'colsample_bytree': 0.700204121543359, 'gamma': 0}. Best is trial 8 with value: 29.37219944150144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [5.7939351447654595, -0.0, 82.32266317973887]\n",
      "[14:36:13] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:36:20] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:36:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:36:31,463]\u001b[0m Trial 9 finished with value: 3.0436380870581545 and parameters: {'n_estimators': 719, 'max_depth': 5, 'learning_rate': 0.07614454464347277, 'subsample': 0.5550335889637175, 'colsample_bytree': 0.5490098130795269, 'gamma': 7}. Best is trial 8 with value: 29.37219944150144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 9.130914261174464]\n",
      "[14:36:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:36:42] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:36:50] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:36:54,521]\u001b[0m Trial 10 finished with value: 6.089205502453921 and parameters: {'n_estimators': 987, 'max_depth': 3, 'learning_rate': 0.09941312402609281, 'subsample': 0.7487861587470614, 'colsample_bytree': 0.8691780260286486, 'gamma': 5}. Best is trial 8 with value: 29.37219944150144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 18.267616507361762]\n",
      "[14:36:59] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:37:08] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:37:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:37:24,951]\u001b[0m Trial 11 finished with value: 18.732583124809377 and parameters: {'n_estimators': 777, 'max_depth': 5, 'learning_rate': 0.06544900609929824, 'subsample': 0.8713463269043176, 'colsample_bytree': 0.6234966372568576, 'gamma': 0}. Best is trial 8 with value: 29.37219944150144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [2.4600162854290675, -0.0, 53.737733088999065]\n",
      "[14:37:28] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:37:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:37:46] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:37:50,889]\u001b[0m Trial 12 finished with value: 9.546474571746304 and parameters: {'n_estimators': 355, 'max_depth': 4, 'learning_rate': 0.053261291210731955, 'subsample': 0.8254481011007634, 'colsample_bytree': 0.814906969517103, 'gamma': 3}. Best is trial 8 with value: 29.37219944150144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [0.17276995845761756, -0.0, 28.46665375678129]\n",
      "[14:37:55] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:38:05] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:38:16] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:38:23,749]\u001b[0m Trial 13 finished with value: 32.525189727572304 and parameters: {'n_estimators': 901, 'max_depth': 7, 'learning_rate': 0.08248515530890209, 'subsample': 0.7281444799136538, 'colsample_bytree': 0.641006720671058, 'gamma': 2}. Best is trial 13 with value: 32.525189727572304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [8.342601667385484, -0.0, 89.23296751533144]\n",
      "[14:38:28] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:38:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:38:45] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:38:51,096]\u001b[0m Trial 14 finished with value: 18.55546078060513 and parameters: {'n_estimators': 940, 'max_depth': 7, 'learning_rate': 0.0830573760274551, 'subsample': 0.7032186063873415, 'colsample_bytree': 0.6226219021579642, 'gamma': 3}. Best is trial 13 with value: 32.525189727572304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [1.792495053682747, -0.0, 53.87388728813264]\n",
      "[14:38:56] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:39:02] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:39:10] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:39:14,156]\u001b[0m Trial 15 finished with value: 2.5573151063417527 and parameters: {'n_estimators': 885, 'max_depth': 7, 'learning_rate': 0.08332593688656612, 'subsample': 0.7289264844607946, 'colsample_bytree': 0.6578850257379276, 'gamma': 8}. Best is trial 13 with value: 32.525189727572304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 7.671945319025259]\n",
      "[14:39:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:39:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:39:32] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:39:35,522]\u001b[0m Trial 16 finished with value: 0.04222837466687381 and parameters: {'n_estimators': 885, 'max_depth': 8, 'learning_rate': 0.09784509961144025, 'subsample': 0.7849365427239774, 'colsample_bytree': 0.7381254865609488, 'gamma': 20}. Best is trial 13 with value: 32.525189727572304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [-0.0, -0.0, 0.12668512400062143]\n",
      "[14:39:40] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:39:57] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:40:14] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:40:27,836]\u001b[0m Trial 17 finished with value: 20.025527597034046 and parameters: {'n_estimators': 719, 'max_depth': 10, 'learning_rate': 0.05956902674226308, 'subsample': 0.6503400552965246, 'colsample_bytree': 0.5967803005214019, 'gamma': 2}. Best is trial 13 with value: 32.525189727572304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [3.6821689861430564, -0.0, 56.394413804959086]\n",
      "[14:40:32] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:40:39] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:40:48] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:40:53,617]\u001b[0m Trial 18 finished with value: 8.812638805326936 and parameters: {'n_estimators': 557, 'max_depth': 9, 'learning_rate': 0.07681403599153656, 'subsample': 0.7837055658731438, 'colsample_bytree': 0.7982550134121199, 'gamma': 5}. Best is trial 13 with value: 32.525189727572304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [0.11001497866389837, -0.0, 26.327901437316907]\n",
      "[14:40:57] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:41:09] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:41:23] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 14:41:32,934]\u001b[0m Trial 19 finished with value: 20.468317211012916 and parameters: {'n_estimators': 411, 'max_depth': 7, 'learning_rate': 0.04259795777736618, 'subsample': 0.6810182845845397, 'colsample_bytree': 0.719607121135183, 'gamma': 2}. Best is trial 13 with value: 32.525189727572304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial done: AUC values on folds: [3.2207547938168206, -0.0, 58.184196839221926]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ace58c3ca018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFIT_XGB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjectie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of finished trials: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         )\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-df048fb86c32>\u001b[0m in \u001b[0;36mobjectie\u001b[0;34m(trial, cv, cv_fold_func)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0md_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0md_valid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_valid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, enable_categorical)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mfeature_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             enable_categorical=enable_categorical)\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         return _from_numpy_array(data, missing, threads, feature_names,\n\u001b[0;32m--> 531\u001b[0;31m                                  feature_types)\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_from_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_numpy_array\u001b[0;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         ctypes.c_int(nthread)))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FIT_XGB = True\n",
    "n_trials = 60\n",
    "\n",
    "if FIT_XGB:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objectie, n_trials)\n",
    "    \n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"Params:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = trial.params\n",
    "best_params['tree_method'] = 'gpu_hist' \n",
    "best_params\n",
    "with open('./params.txt', \"w\", encoding='utf-8') as f:\n",
    "    f.write(str(best_params))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(X_train, y_labels)\n",
    "clf = xgb.train(best_params, dtrain, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-reverse",
   "metadata": {},
   "source": [
    "## Treelite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = treelite.Model.from_xgboost(clf)\n",
    "toolchain = 'gcc'\n",
    "model.export_lib(toolchain=toolchain, libpath='./mymodel.so', params={'parallel_comp': 32}, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hindu-energy",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'treelite_runtime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cbbf2640efde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreelite_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mymodel.so'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'treelite_runtime' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = treelite_runtime.Predictor('./mymodel.so', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def fast_fillna(array, values):\n",
    "    if np.isnan(array.sum()):\n",
    "        array = np.where(np.isnan(array), values, array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import janestreet\n",
    "env = janestreet.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "PCA_appied = False\n",
    "opt_th = 0.505\n",
    "tmp = np.zeros(len(feature_names))\n",
    "for (test_df, prediction_df) in tqdm(iter_test):\n",
    "    if test_df['weight'].values[0] > 0:\n",
    "        x_tt = test_df.loc[:, feature_names].values\n",
    "        x_tt[0, :] = fast_fillna(x_tt[0, :], tmp)\n",
    "        tmp = x_tt[0, :]\n",
    "        if PCA_appied:\n",
    "#             y_preds = clf.predict(pca.transform(x_tt))\n",
    "            y_preds = predictor.predict(treelite_runtime.DMatrix(pca.transform(x_tt)))\n",
    "        else:\n",
    "#             y_preds = clf.predict(x_tt)\n",
    "            y_preds = predictor.predict(treelite_runtime.DMatrix(x_tt))\n",
    "        prediction_df[\"action\"].values[0] = int(y_preds >= 0.5)\n",
    "    else:\n",
    "        prediction_df[\"action\"].values[0] = 0\n",
    "    env.predict(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-tourism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
