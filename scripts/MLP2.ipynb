{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organic-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, time, gc, random\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "import janestreet\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import dump, load\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fantastic-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "historic-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataset:\n",
    "    def __init__(self, df, train_features, train_labels):\n",
    "        self.features = df[train_features].values\n",
    "        self.label = (df[train_labels] > 0).astype(int).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.features[idx], dtype=torch.float),\n",
    "            'label': torch.tensor(self.label[idx], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cognitive-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-effect",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "necessary-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 52s, sys: 27.2 s, total: 14min 19s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = dt.fread('/kaggle/working/input/train.csv').to_pandas()\n",
    "train = train.query('date > 85').reset_index(drop=True)\n",
    "train = train.loc[train.weight > 0].reset_index(drop = True)\n",
    "\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "f_mean = train[features[1:]].mean()\n",
    "train[features[1:]] = train[features[1:]].fillna(f_mean)\n",
    "f_mean = f_mean.values\n",
    "\n",
    "train['action'] = (train['resp'] > 0).astype('int')\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "married-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_colunms, num_labels):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm0 = nn.BatchNorm1d(num_colunms)\n",
    "        self.dropout0 = nn.Dropout(0.2)\n",
    "\n",
    "        self.dense1 = nn.Linear(num_colunms, 384)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(384)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.dense2 = nn.Linear(384, 896)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(896)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "        self.dense3 = nn.Linear(896, 896)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(896)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.dense4 = nn.Linear(896, 394)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(394)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "\n",
    "        self.dense5 = nn.Linear(394, num_labels)\n",
    "\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "        self.PReLU = nn.PReLU()\n",
    "        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        # self.GeLU = nn.GELU()\n",
    "        self.RReLU = nn.RReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm0(x)\n",
    "        x = self.dropout0(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = x * F.sigmoid(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = x * F.sigmoid(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = x * F.sigmoid(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.dense4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = x * F.sigmoid(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.dense5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "finnish-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        features = data['features'].to(device)\n",
    "        label = data['label'].to(device)\n",
    "        outputs = model(features)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        final_loss += loss.item()\n",
    "    final_loss /= len(dataloader)\n",
    "    return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Time:14.64s, Loss 0.6913047307170928\n",
      "Epoch:1, Time:13.57s, Loss 0.6892876237009963\n",
      "Epoch:2, Time:13.43s, Loss 0.6887070592492819\n",
      "Epoch:3, Time:13.24s, Loss 0.6883050406662127\n",
      "Epoch:4, Time:13.79s, Loss 0.6879889594080547\n",
      "Epoch:5, Time:13.27s, Loss 0.6876410537709793\n",
      "Epoch:6, Time:13.80s, Loss 0.6873247679322958\n",
      "Epoch:7, Time:13.10s, Loss 0.686977336804072\n",
      "Epoch:8, Time:13.17s, Loss 0.6867044504421452\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "num_colunms = len(features)\n",
    "num_labels = len(resp_cols)\n",
    "batch_size = 4096\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_set = MarketDataset(train, features, resp_cols)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = Model(num_colunms=num_colunms, num_labels=num_labels)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = SmoothBCEwLogits(smoothing=label_smoothing)\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_fn(model, optimizer, None, loss_fn, train_loader, device)\n",
    "    end = time.time()\n",
    "    print('Epoch:{}, Time:{:.2f}s, Loss {}'.format(epoch, end - start, train_loss))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-metabolism",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = janestreet.make_env()\n",
    "env_iter = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.503\n",
    "model.eval()\n",
    "for (test_df, pred_df) in tqdm(env_iter):\n",
    "    if test_df['weight'].item() > 0:\n",
    "        x_tt = test_df.loc[:, features].values\n",
    "        if np.isnan(x_tt[:, 1:].sum()):\n",
    "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "        pred = np.median(model(torch.tensor(x_tt, dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy())\n",
    "        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "    env.predict(pred_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
